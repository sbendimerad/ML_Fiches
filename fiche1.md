# ğŸ—‚ï¸ PARTIE 1 â€” Expliquer un projet ML en entretien (RH et Tech)

## ğŸ¯ Structure pour RH (version simplifiÃ©e, orientÃ©e mÃ©tier)

- **Nom du projet :**  
  _Ex : PrÃ©diction de dÃ©part Ã  la concurrence_

- **PÃ©riode :**  
  _Quand le projet a-t-il Ã©tÃ© rÃ©alisÃ© ?_

- **Ã‰quipe :**  
  _Combien de personnes ont contribuÃ© ? Quel rÃ´le ?_

- **Objectif du projet :**  
  _Ex : RÃ©duire le churn client en prÃ©disant les dÃ©parts_

- **Contexte :**  
  - DonnÃ©es collectÃ©es sur un territoire spÃ©cifique  
  - Variables disponibles : historique client, usage, satisfaction, etc.  
  - Nombre de lignes / colonnes  
  - Avant : dÃ©cisions prises a posteriori

- **Outils utilisÃ©s :**  
  - Python (Pandas, Scikit-learn)  
  - MLflow pour le suivi  
  - RÃ©sultats : fichiers / BDD / API

- **Utilisation des rÃ©sultats :**  
  _Ex : Score de churn transmis aux Ã©quipes marketing_

- **ROI / Impact attendu :**  
  _Ex : RÃ©duction de 15% du churn = Ã©conomie de Xâ‚¬_

- **Ã‰tat actuel du projet :**  
  _En production / En test / En pause_

---

## ğŸ§  Structure pour Tech (plus dÃ©taillÃ©e)

- **ProblÃ¨mes rencontrÃ©s :**
  - Valeurs manquantes : `IterativeImputer`, `KNNImputer`
  - Outliers : IQR / rÃ¨gles mÃ©tier
  - DonnÃ©es dÃ©sÃ©quilibrÃ©es : SMOTE
  - CorrÃ©lation forte : PCA

- **MÃ©thodologie ML :**
  - Baseline â†’ modÃ¨les linÃ©aires â†’ modÃ¨les non-linÃ©aires â†’ modÃ¨les avancÃ©s

- **Algorithmes testÃ©s :**
  - DummyClassifier
  - RÃ©gression logistique
  - SVM Classifier
  - RandomForestClassifier
  - XGBoost

- **Validation :**
  - Cross-validation + GridSearchCV

- **HyperparamÃ¨tres :**
  - `n_estimators`, `max_depth`, `learning_rate`â€¦

- **MÃ©triques :**
  - Accuracy, Precision, Recall, F1-Score, Temps de calcul

---

# ğŸ—‚ï¸ PARTIE 2 â€” Questions et Concepts ML

---

## ğŸ“Œ 1. Outliers

- **DÃ©tection simple :**
  - Boxplot / histogramme
  - MÃ©thode IQR ou Z-score

- **DÃ©cision mÃ©tier :**
  - Outlier ou pas selon le contexte

- **Traitement :**
  - Suppression
  - Winsorization
  - Log-transform
  - ModÃ¨les de dÃ©tection : Isolation Forest / LOF

---

## ğŸ“Œ 2. Valeurs manquantes

- **Ã‰tape 1 â€” Analyse**
  - % de NaN
  - Visualisation `missingno`

- **Ã‰tape 2 â€” Imputation simple**
  - NumÃ©rique : moyenne / mÃ©diane
  - CatÃ©gorique : mode / "manquant"

- **Ã‰tape 3 â€” Imputation avancÃ©e**
  - `IterativeImputer`
  - `KNNImputer`
  - Nouvelle variable â€œis_missingâ€

---

## ğŸ“Œ 3. DÃ©marche ML classique

1. ComprÃ©hension du problÃ¨me
2. EDA
3. Nettoyage
4. Split train/test (stratify pour classification)
5. Baseline
6. ModÃ¨les progressifs (linÃ©aires â†’ arbres â†’ boosting)
7. HyperparamÃ¨tres (GridSearchCV)
8. Ã‰valuation (F1, MAEâ€¦)
9. InterprÃ©tation (SHAP, LIME)
10. DÃ©ploiement (pickle, FastAPI)

---

## ğŸ“Œ 4. Concepts fondamentaux

### ğŸ”¸ Overfitting / Underfitting
- **Overfitting :** bien sur train, mauvais sur test
- **Underfitting :** mauvais partout

### ğŸ”¸ Biais / Variance
- **Biais Ã©levÃ© :** modÃ¨le trop simple
- **Variance Ã©levÃ©e :** modÃ¨le trop complexe

---

## ğŸ“Œ 5. DonnÃ©es dÃ©sÃ©quilibrÃ©es

- Ex : 95% classe 0
- **ProblÃ¨me :** Accuracy trop flatteuse
- **Solutions :**
  - MÃ©triques : F1-score, recall
  - Techniques : SMOTE / undersampling

---

## ğŸ“Œ 6. Bagging vs Boosting

| Bagging                    | Boosting                      |
|---------------------------|-------------------------------|
| Arbres train parallÃ¨le    | ModÃ¨les entraÃ®nÃ©s en sÃ©rie   |
| RÃ©duit variance           | RÃ©duit biais                  |
| Exemple : Random Forest   | Exemple : XGBoost             |

---

## ğŸ“Œ 7. Random Forest (trÃ¨s simplifiÃ©)

- EntraÃ®ne plein dâ€™arbres sur des Ã©chantillons diffÃ©rents
- Chaque arbre vote
- Fonctionne bien sans rÃ©glage complexe
- Se base sur **indice de Gini** pour les splits

---

## ğŸ“Œ 8. OneHotEncoder

- **Avantage :** ne suppose pas d'ordre
- **InconvÃ©nient :** explosion de dimensions
- â• Bien pour arbres
- â– Ã€ combiner avec PCA si trop de colonnes

---

## ğŸ“Œ 9. Cross-validation

- RÃ©duit les biais liÃ©s Ã  un seul split
- Classique : `KFold` (ou `StratifiedKFold`)
- TimeSeries : `TimeSeriesSplit`

> _ğŸ–¼ï¸ Place ici une image du schÃ©ma de cross-validation_

---

## ğŸ“Œ 10. Feature Selection

- **MÃ©thodes :**
  - CorrÃ©lation
  - Lasso (supprime)
  - Ridge (rÃ©duit)
  - SHAP / importance des features
- RÃ©entraÃ®ner avec top K features

---

## ğŸ“Œ 11. RÃ©gression logistique

- ModÃ¨le linÃ©aire + fonction **sigmoÃ¯de**
- PrÃ©dit une **probabilitÃ©**
- Seuil Ã  0.5 â†’ classe 0 ou 1
- InterprÃ©table (coefficients)

---

## ğŸ“Œ 12. RÃ©seau de neurones (step-by-step)

1. DonnÃ©es passent dans la couche dâ€™entrÃ©e
2. Multiplication des poids + ajout biais
3. Activation (ReLU, Sigmoidâ€¦)
4. Calcul dâ€™une **perte** (loss)
5. **Backpropagation** : on propage lâ€™erreur en arriÃ¨re
6. **Mise Ã  jour des poids** (descente de gradient)

### ğŸ“ Vocabulaire
- **Epoch :** 1 passage complet sur le jeu d'entraÃ®nement
- **Batch :** portion des donnÃ©es
- **Forward pass :** prÃ©diction
- **Backward pass :** correction

---

